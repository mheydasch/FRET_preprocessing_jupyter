{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply pixel classifier on all images in a folder,  create corresponding mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/opt/anaconda3/lib/python3.7/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "from skimage.morphology import binary_erosion\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import glob\n",
    "import os\n",
    "import pickle as pkl\n",
    "from skimage import io\n",
    "from csbdeep.utils import normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.morphology import square\n",
    "import scipy\n",
    "from skimage.segmentation import expand_labels\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.realpath('/Users/max/Desktop/Scripts_for_max/'))\n",
    "from semantic_segmentation import init_VGG16_pyramid, fd_VGG16_pyramid\n",
    "from magicgui import magicgui\n",
    "import napari\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_mask_from_labels(labels):\n",
    "    '''takes label mask, shrinks objects and subtracts from original image.'''\n",
    "    stim_width = 10\n",
    "    footprint = np.ones((stim_width,stim_width))\n",
    "    labels_b = labels>0\n",
    "    labels_b_ero = binary_erosion(labels_b,footprint)\n",
    "    labels_b_sub = np.logical_xor(labels_b,labels_b_ero)\n",
    "    labels_b_sub = labels_b_sub.astype('uint8')\n",
    "    labels_sub = np.multiply(labels_b_sub,labels)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    props = skimage.measure.regionprops(labels)\n",
    "    for prop in props[:]:\n",
    "        df_spot = pd.DataFrame({'cell_label': [prop.label],'cell_x': [prop.centroid[0]], 'cell_y':[prop.centroid[1]], 'cell_area': [prop.area],'stim_width':[stim_width]})\n",
    "        df = df.append(df_spot)\n",
    "\n",
    "    return labels_b_sub,df\n",
    "\n",
    "def frame_to_labels(frame):\n",
    "    #f_h2b = frame[1,:,:].copy()\n",
    "    f_h2b = frame[:,:].copy()\n",
    "    f_h2b_scaled = normalize(f_h2b, 5,95)\n",
    "    features = fd_VGG16_pyramid(f_h2b_scaled,models,shapes)\n",
    "    to_predict = features.reshape(np.shape(features)[0]*np.shape(features)[1],np.shape(features)[2])\n",
    "    prediction_list = clf.predict_proba(to_predict)[:,0]\n",
    "    prediction_img = np.reshape(prediction_list, f_h2b_scaled.shape)\n",
    "    #now run watershed on segmentaion, using no seed\n",
    "    prediction_img = prediction_img>0.5\n",
    "    prediction_img = skimage.morphology.erosion(prediction_img, square(5))\n",
    "    prediction_img = skimage.morphology.remove_small_objects(prediction_img, min_size = 100**2)\n",
    "    prediction_img = scipy.ndimage.morphology.binary_fill_holes(prediction_img)\n",
    "        \n",
    "    #labels = skimage.segmentation.watershed(-distance_img, mask = prediction_img)#, mask=prediction_img>0.5)\n",
    "    labels = skimage.segmentation.watershed(~prediction_img, mask = prediction_img)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the classifier you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/Users/max/Desktop/Scripts_for_max/classifier_max_2021-10-15_DLC1.pkl\", \"rb\")\n",
    "clf = pkl.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/Users/max/Desktop/Scripts_for_max/classifier_max_2021-10-15_DLC1.pkl\", \"wb\")\n",
    "pkl.dump(clf, file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1_flatfield=np.array(Image.open('/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_5/FRET_5/Flatfield_s1_/FRET/Flatfield_s1_w26TIRFFRETacceptor_t3.tif'))\n",
    "ch2_flatfield=np.array(Image.open('/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_5/FRET_5/Flatfield_s1_/CFP/Flatfield_s1_w16TIRF-CFP_t2.tif'))\n",
    "ch1='FRET'\n",
    "ch2='CFP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bg_calculation(image):\n",
    "    hist, bins = np.histogram(image, bins=50)\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "#    plt.bar(center, hist, align='center', width = width)\n",
    "#    plt.ylim(0,450000)\n",
    "#    plt.xlim(0,750)\n",
    "    bg = np.mean(bins[0:4])\n",
    "    return bg, #plt.show(\n",
    "\n",
    "# Actual background substraction\n",
    "def background_sub(image, bg):\n",
    "    global bg_mask\n",
    "    bg_z_image = image - bg\n",
    "    bg_mask = np.zeros_like(bg_z_image)\n",
    "    bg_mask[bg_z_image > 0] = 1\n",
    "    bg_z_image = bg_mask*bg_z_image\n",
    "    bg_z_image = bg_z_image.astype(np.float32) \n",
    "    return bg_z_image\n",
    "\n",
    "def bg_correct(image):\n",
    "    bg_calc = bg_calculation(image)\n",
    "    corr_im = background_sub(image,bg_calc[0])\n",
    "    return corr_im\n",
    "\n",
    "def image_ratioing(f, c, path, FRET):\n",
    "    FRETimage=f\n",
    "    CFPimage=c\n",
    "    FRETratio=np.divide(FRETimage, CFPimage)\n",
    "    FRETratiotif=Image.fromarray(FRETratio)\n",
    "    outpath=os.path.join(path, 'ratio')\n",
    "    createFolder(outpath)\n",
    "    savestr=os.path.join(outpath,FRET.split('.')[0]+'_ratio'+'.TIF')\n",
    "    FRETratiotif.save(savestr)\n",
    "    print('saving: ', savestr)\n",
    "    \n",
    "def flatfield_preprocessing(img, flatfield):\n",
    "    ch1image=np.array(Image.open(os.path.join(path, img)))\n",
    "    ch1corrected=np.divide(ch1image, flatfield)\n",
    "    bg_corrected=bg_correct(ch1corrected)\n",
    "    plt.imshow(bg_corrected, cmap = 'gray')\n",
    "    return bg_corrected\n",
    "def flatfield_correction(path, ch1='FRET', ch2='CFP', timelapse=False):\n",
    "   files=os.listdir(path)\n",
    "   if timelapse == False:\n",
    "       pattern = re.compile('(?P<Imagename>[^w]*).*(?P<Channel>FRET|CFP).*')\n",
    "   if timelapse == True:       \n",
    "       pattern = re.compile('(?P<Imagename>[^w]*).*(?P<Channel>FRET|CFP).*(?P<Timepoint>t[0-9]+).*')\n",
    "\n",
    "   FRET_files=[i for i in files if ch1 in i]\n",
    "   CFP_files=[i for i in files if ch2 in i] \n",
    "   for FRET in FRET_files:\n",
    "        try:\n",
    "            if timelapse==False:\n",
    "                FRETname=re.search(pattern, FRET).group('Imagename')\n",
    "            if timelapse == True:       \n",
    "                FRETname=re.search(pattern, FRET).group('Imagename', 'Timepoint')\n",
    "\n",
    "            FRET_corrected=flatfield_preprocessing(FRET, ch1_flatfield)\n",
    "            for CFP in CFP_files:\n",
    "                if timelapse==False:\n",
    "                    CFPname=re.search(pattern, CFP).group('Imagename')\n",
    "                    CFPname=re.search(pattern, CFP).group('Imagename', 'Timepoint')\n",
    "\n",
    "                if CFPname==FRETname:\n",
    "                    try:\n",
    "                        CFP_corrected=flatfield_preprocessing(CFP, ch2_flatfield)\n",
    "                        image_ratioing(FRET_corrected, CFP_corrected, path, FRET)\n",
    "                        print('processing ', FRET)\n",
    "                    except OSError as e:\n",
    "                        print (e)     \n",
    "            \n",
    "        except OSError as e:\n",
    "            print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input and output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/'\n",
    "output_folder_segmentation = '/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/cp.out1/output/'\n",
    "output_folder_mask = '/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/cp.out1/output/stim_mask/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 333 input files.\n",
      "Last file: /Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/flatfield_3_w26TIRFFRETacceptor.TIF\n"
     ]
    }
   ],
   "source": [
    "filenames = sorted(glob.glob(os.path.join(input_folder,'*.TIF')))\n",
    "print(f'Found {len(filenames)} input files.')\n",
    "print(f'Last file: {filenames[-2]}')\n",
    "raw = io.imread(filenames[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/'\n",
    "fov = 0\n",
    "raw = io.imread(filenames[4])\n",
    "frame = raw\n",
    "norm_min = 5\n",
    "norm_max = 95\n",
    "f_h2b = frame[:,:].copy()\n",
    "annotation_frame = normalize(f_h2b, norm_min,norm_max)\n",
    "norm_min = 5\n",
    "norm_max = 95\n",
    "shapes = [(512,512),(64,64),(32,32)]\n",
    "#shapes = [(540,540),(68,68),(32,32)]\n",
    "models = init_VGG16_pyramid(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/opt/anaconda3/lib/python3.7/site-packages/napari/_qt/__init__.py:54: UserWarning: \n",
      "\n",
      "IMPORTANT:\n",
      "You are using QT version 5.12.1, but version 5.12 was also found in your environment.\n",
      "This usually happens when you 'conda install' something that also depends on PyQt\n",
      "*after* you have pip installed napari (such as jupyter notebook).\n",
      "You will likely run into problems and should create a fresh environment.\n",
      "If you want to install conda packages into the same environment as napari,\n",
      "please add conda-forge to your channels: https://conda-forge.org\n",
      "\n",
      "  warn(message=warn_message)\n"
     ]
    }
   ],
   "source": [
    "#create the classifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# create feature extractor and apply \n",
    "#shapes = [(1024,1024),(512,512),(256,256),(128,128),(64,64)]\n",
    "shapes = [(512,512),(64,64),(32,32)]\n",
    "models = init_VGG16_pyramid(shapes)\n",
    "features = fd_VGG16_pyramid(annotation_frame,models,shapes)\n",
    "\n",
    "\n",
    "@magicgui(call_button='train classifier')\n",
    "def clf_widget():\n",
    "    #run everytime the train button is pressed\n",
    "    #extract the labels\n",
    "    annotations = np.array(labels_layer.data)\n",
    "    X,y = annotations_to_tensor(features,annotations)\n",
    "    clf.fit(X, y) #train the classifier on the new labels\n",
    "    #now predict the rest of the image with the new clf\n",
    "    to_predict = features.reshape(np.shape(features)[0]*np.shape(features)[1],np.shape(features)[2])\n",
    "    prediction_list = clf.predict_proba(to_predict)[:,0]\n",
    "    prediction_img = np.reshape(prediction_list, annotation_frame.shape)\n",
    "    \n",
    "    #display the new prediciton\n",
    "    prediction_layer.visible = True\n",
    "    prediction_layer.data = prediction_img\n",
    "    return clf\n",
    "\n",
    "def annotations_to_tensor(feature_matrix,mask):\n",
    "    #feature matrix dim: [x,y,nb_features]\n",
    "    #possible mask elements: 0: not annotated, int[1,2]: class annotation\n",
    "    y_labels=[] #where class labels are stored\n",
    "    X_features=[] #where feature vectors are stored\n",
    "    for x,y in np.argwhere(mask!=0):\n",
    "        y_labels.append(mask[x,y])\n",
    "        #X_features.append(feature_matrix[x,y,:])\n",
    "        X_features.append(feature_matrix[x,y,])\n",
    "    #turn list into np array\n",
    "    X_features = np.asarray(X_features)\n",
    "    return X_features,y_labels\n",
    "\n",
    "viewer = napari.view_image(annotation_frame, name=\"My Image\")\n",
    "\n",
    "\n",
    "labels_layer = viewer.add_labels(np.zeros_like(annotation_frame).astype(int), seed = 0)\n",
    "viewer.window.add_dock_widget(clf_widget)\n",
    "prediction_layer = viewer.add_image(np.zeros_like(annotation_frame),colormap='PiYG')\n",
    "prediction_layer.visible = False\n",
    "prediction_layer.name = \"Classifier prediction\"\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder:  /Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/cp.out1/output/mask already exists\n",
      "Folder:  /Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/cp.out1/output/stim_mask already exists\n"
     ]
    }
   ],
   "source": [
    "## Create the required folders \n",
    "def create_folders(path, directory):\n",
    "    for i in directory:\n",
    "        iDir=os.path.join(path, i)\n",
    "        try:\n",
    "            if not os.path.exists(iDir):\n",
    "                os.makedirs(iDir)\n",
    "                print('Created folder: ', iDir)\n",
    "            else: \n",
    "                print('Folder: ', iDir, 'already exists')\n",
    "        except OSError:\n",
    "            print ('Error: Creating directory. ' + iDir)\n",
    "required_folders = ['mask', 'stim_mask'] #leave this\n",
    "\n",
    "create_folders(output_folder_segmentation,required_folders)  #leave this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the segmentation on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_10_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_11_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_12_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_13_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_14_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_15_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_16_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_17_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_18_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_19_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_1_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_20_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_21_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_22_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_23_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_24_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_25_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_26_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_27_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_28_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_29_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_2_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_30_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_31_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_32_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_33_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_34_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_35_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_36_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_37_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_38_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_39_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_3_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_40_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_41_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_42_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_43_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_44_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_45_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_46_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_47_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_48_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_49_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_4_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_50_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_51_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_52_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_53_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_54_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_55_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_56_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_57_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_5_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_6_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_7_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_8_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/1B2_9_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_10_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_11_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_12_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_13_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_14_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_15_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_16_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_17_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_18_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_19_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_1_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_20_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_21_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_22_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_23_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_24_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_25_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_26_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_27_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_28_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_29_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_2_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_30_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_31_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_32_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_33_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_34_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_35_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_36_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_37_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_38_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_39_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_3_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_40_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_41_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_42_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_43_w26TIRFFRETacceptor.TIF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_44_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_45_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_46_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_47_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_48_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_49_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_4_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_50_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_5_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_6_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_7_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_8_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52_9_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/REF52__w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/flatfield_1_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/flatfield_2_w26TIRFFRETacceptor.TIF\n",
      "/Volumes/imaging.data/Max/REF52/DLC_1/FRET/FRET_11_late/flatfield_3_w26TIRFFRETacceptor.TIF\n"
     ]
    }
   ],
   "source": [
    "shapes = [(512,512),(64,64),(32,32)]\n",
    "models = init_VGG16_pyramid(shapes)\n",
    "frame_segmented = frame_to_labels(raw)\n",
    "for i, filename in enumerate(filenames):\n",
    "    if 'FRET' in filename.split('/')[-1]:\n",
    "        frame = io.imread(filename)\n",
    "        print(filename)\n",
    "        \n",
    "        # if input image has multiple channels, select the correct one here:\n",
    "        #frame = frame[channel_nb,:,:] #where channel_nb is the channel you want to segment on\n",
    "        frame_segmented = frame_to_labels(frame)\n",
    "        frame_mask, table = spot_mask_from_labels(frame_segmented)\n",
    "        if i == 0:\n",
    "            plt.imshow(frame_segmented)\n",
    "            plt.show()\n",
    "            plt.imshow(frame_mask)\n",
    "            plt.show()\n",
    "            break\n",
    "        io.imsave(os.path.join(output_folder_segmentation,'stim_mask', os.path.basename(filename).split('.')[0]+ 'stimmask' +'.tiff'), frame_mask, check_contrast=False)\n",
    "        io.imsave(os.path.join(output_folder_segmentation, 'mask', os.path.basename(filename).split('.')[0] + 'mask'+'.tiff'), frame_segmented, check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
